# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/120QLK-UaEbcdHjqaesM_iYQKTXi1o8sP
"""

import numpy as np
import pandas as pd
from datetime import datetime
#import glob
#import seaborn as sns
#import re
#import os
#import io

from google.colab import drive
drive.mount('/content/drive', force_remount = True)

#load the data in
data = pd.read_csv('drive/My Drive/AIML427/US_Accidents_Dec21_updated.csv')
data.head()

print(data.dtypes)

data1 = data

data = data1

data['Start_Time'] = pd.to_datetime(data['Start_Time'])
data['Year'] = data['Start_Time'].dt.year

nmonth = data['Start_Time'].dt.month
data['Month'] = nmonth

data['Weekday']= data['Start_Time'].dt.weekday

Months_days = np.cumsum(np.array([0,31,28,31,30,31,30,31,31,30,31,30,31]))
nday = [Months_days[arg-1] for arg in nmonth.values]
nday = nday + data["Start_Time"].dt.day.values
data['Day'] = nday

data['Hour'] = data['Start_Time'].dt.hour

data.loc[:4,['Start_Time', 'Year', 'Month', 'Weekday', 'Day', 'Hour']]

# Idea from and base of code retrieved https://www.kaggle.com/jingzongwang/usa-car-accidents-severity-prediction#1-OVERVIEW-&-PREPROCESSING

"""Replace Missing weather data with the mean based on the location and time of year"""

replace_na=['Temperature(F)','Humidity(%)','Pressure(in)','Visibility(mi)','Wind_Speed(mph)','Precipitation(in)']
print("The number of remaining missing values: ")
for i in replace_na:
  data[i] = data.groupby(['Airport_Code','Month'])[i].apply(lambda x: x.fillna(x.mean()))
  print( i + " : " + data[i].isnull().sum().astype(str))

df_source = data.groupby(['Severity','Year']).size().reset_index().pivot(\
     index='Year', values=0)
df_source.plot(kind='line', stacked=False, title='Yeat Count by Sources')

new_df = data[data['Year'] == 2016]
df_2017 = data[data['Year'] == 2017]
df_2018 = data[data['Year'] == 2018]
df_2019 = data[data['Year'] == 2019]
df_2020 = data[data['Year'] == 2020]
df_2021 = data[data['Year'] == 2021]

data['Severity'].value_counts()

new_df['Severity'].value_counts()

df_2017['Severity'].value_counts()

df_2018['Severity'].value_counts()

df_2019['Severity'].value_counts()

df_2020['Severity'].value_counts()

df_2021['Severity'].value_counts()

weather_types ='!'.join(data['Weather_Condition'].dropna().unique().tolist())
weather_types = np.unique(np.array(re.split(
    "!|\s/\s|\sand\s|\swith\s|Partly\s|Mostly\s|Blowing\s|Freezing\s", weather_types))).tolist()
print("Weather Conditions: ", weather_types)

#Simplify wind direction to the cardinal directions
data.loc[(data['Wind_Direction']=='NNE')|(data['Wind_Direction']=='NNW'),'Wind_Direction'] = 'North'
data.loc[(data['Wind_Direction']=='ENE')|(data['Wind_Direction']=='ESE'),'Wind_Direction'] = 'East'
data.loc[(data['Wind_Direction']=='SSE')|(data['Wind_Direction']=='SSW'),'Wind_Direction'] = 'South'
data.loc[(data['Wind_Direction']=='WNW')|(data['Wind_Direction']=='WSW'),'Wind_Direction'] = 'West'
data.loc[(data['Wind_Direction']=='VAR'),'Wind_Direction'] = 'Variable'

#create new fields for each direction (yes/no).  convert to float
data['North'] = np.where(data['Wind_Direction'].str.contains('North', case=False, na = False), 1, 0)
data['North'] = data["North"].astype(float)

data['East'] = np.where(data['Wind_Direction'].str.contains('East', case=False, na = False), 1, 0)
data['East'] = data["East"].astype(float)

data['South'] = np.where(data['Wind_Direction'].str.contains('South', case=False, na = False), 1, 0)
data['South'] = data["South"].astype(float)

data['West'] = np.where(data['Wind_Direction'].str.contains('West', case=False, na = False), 1, 0)
data['West'] = data["West"].astype(float)

data['Variable'] = np.where(data['Wind_Direction'].str.contains('Variable', case=False, na = False), 1, 0)
data['Variable'] = data["Variable"].astype(float)

data['Calm'] = np.where(data['Wind_Direction'].str.contains('Calm', case=False, na = False), 1, 0)
data['Calm'] = data["Calm"].astype(float)


#Simplify weather condition and create new fields for each. convert to float
data['Clear'] = np.where(data['Weather_Condition'].str.contains('Clear|Fair', case=False, na = False), 1, 0)
data['Clear'] = data["Clear"].astype(float)

data['Cloudy'] = np.where(data['Weather_Condition'].str.contains('Cloud|Overcast', case=False, na = False), 1, 0)
data['Cloudy'] = data["Cloudy"].astype(float)

data['Raining'] = np.where(data['Weather_Condition'].str.contains('Rain|Rain Shower', case=False, na = False), 1, 0)
data['Raining'] = data["Raining"].astype(float)

data['Heavy_Rain'] = np.where(data['Weather_Condition'].str.contains('Heavy Rain|storm|Heavy T-Storm|Heavy Thunderstorms', case=False, na = False), 1, 0)
data['Heavy_Rain'] = data["Heavy_Rain"].astype(float)

data['Snowing'] = np.where(data['Weather_Condition'].str.contains('Snow|Sleet|Ice|Light Snow', case=False, na = False), 1, 0)
data['Snowing'] = data["Snowing"].astype(float)

data['Heavy_Snow'] = np.where(data['Weather_Condition'].str.contains('Heavy Snow|Heavy Sleet|Heavy Ice Pellets|Snow Showers|Squalls', case=False, na = False), 1, 0)
data['Heavy_Snow'] = data["Heavy_Snow"].astype(float)

data['Fog'] = np.where(data['Weather_Condition'].str.contains('Fog|Partial Fog|Patches of Fog', case=False, na = False), 1, 0)
data['Fog'] = data["Fog"].astype(float)

# Idea from and base of code retrieved https://www.kaggle.com/jingzongwang/usa-car-accidents-severity-prediction#1-OVERVIEW-&-PREPROCESSING

#Convert all remaining boolean variables to float
data["Amenity"] = data["Amenity"].astype(float)
data["Bump"] = data["Bump"].astype(float)
data["Crossing"] = data["Crossing"].astype(float)
data["Give_Way"] = data["Give_Way"].astype(float)
data["Junction"] = data["Junction"].astype(float)
data["No_Exit"] = data["No_Exit"].astype(float)
data["Railway"] = data["Railway"].astype(float)
data["Roundabout"] = data["Roundabout"].astype(float)
data["Station"] = data["Station"].astype(float)
data["Stop"] = data["Stop"].astype(float)
data["Traffic_Calming"] = data["Traffic_Calming"].astype(float)
data["Traffic_Signal"] = data["Traffic_Signal"].astype(float)

#Reposition the Severity column for ease of use in java
severity = data['Severity']
data = data.drop(['Severity'],axis=1)
data['Severity'] = severity

#drop unnecessary features
data = data.drop(['ID','End_Lat', 'End_Lng', 'Description', 'Number', 'Timezone', 'Turning_Loop', 'Country', 'End_Time','Wind_Direction','Weather_Condition',
                  'Wind_Chill(F)','Weather_Timestamp','Airport_Code','Street','Start_Lat','Start_Lng','Start_Time','City','County','State','No_Exit','Roundabout','Railway',
                  'Traffic_Calming','Give_Way','Bump','Amenity'], axis = 1)

#Drop any remaining null values
data.dropna()

#convert features to a data type that we can load into a JavaRDD

data["Zipcode"] = data["Zipcode"].astype(int)

x=data['Side'].value_counts()
item_type_mapping={}
item_list=x.index
for i in range(0,len(item_list)):
    item_type_mapping[item_list[i]]=i

data['Side'] = data['Side'].map(lambda x:item_type_mapping[x]) 

Convert_data=['Sunrise_Sunset','Civil_Twilight','Nautical_Twilight','Astronomical_Twilight']
for j in Convert_data:
  x=data[j].value_counts()
  item_type_mapping={}
  item_list=x.index
  for i in range(0,len(item_list)):
      item_type_mapping[item_list[i]]=i

  data[j] = np.where(data[j].str.contains('Night', case=False, na = False), 1, 0)

data.loc[(data['Severity']==1),'Severity'] = 'Moderate'
data.loc[(data['Severity']==2),'Severity'] = 'Moderate'
data.loc[(data['Severity']==3),'Severity'] = 'Major'
data.loc[(data['Severity']==4),'Severity'] = 'Severe'

with open('drive/My Drive/AIML427/US_Accidents_Dec21_No_Minor.csv', 'w', encoding = 'utf-8-sig') as f:
  data.to_csv(f,header=None,index=False)